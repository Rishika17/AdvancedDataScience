# AdvancedDataScience
Question Answering model
Abstract—This project explores the idea of creating A Question Answering in LSTMs model using SQUAD dataset. Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. This project uses the SQUAD dataset, Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, orspan, from the corresponding reading passage, or the question might be unanswerable. A clean function is used to clean and preprocess the dataset. Once the data has been preprocessed, various new features are added to the dataset. First, the question length is calculated. Next, another feature ie the maximum IR wiki score which is basically the measure of relevance of a specific Wikipedia page is calculated. Following this, a new feature which is the difference between the answer with max ir score and the answer with the second highest IR score is calculated . After this new feature which checks if the true answer matches the answer with maximum ir score.Then we embed the category column using Weight Of Evidence Encoding. Following this Topic Modeling is done using LDA model to create 4 more topics to understand the features more closely.Then the data is regularized and the binary classification is done using Support Vector Machine. The loss is calculated at each step of every epoch. After the completion of 20 epochs, the process of LSTM is performed. The total loss of the model is computed, and the performance is evaluated using different metrics like confusion matrix. For running the neural networks involved in this project, Google Colab's free GPU has been very helpful. The results produced by the LSTM are those generated after 10 epochs.

